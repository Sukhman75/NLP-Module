{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP_Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person bleeding\n",
      "bleeding\n",
      "-1\n",
      "Time-Taken: 0.0009982585906982422\n"
     ]
    }
   ],
   "source": [
    "#libraries to be used\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import time\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk import word_tokenize\n",
    "\n",
    "\n",
    " \n",
    "start=time.time() \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    " \n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        Remove punctuation and stopwords, lemmatize the text, tokenize the sentence into tokens\n",
    "    \"\"\"    \n",
    "    #text = text.replace(\"\\n\", \" \")\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = \" \".join([lemmatizer.lemmatize(word) for word in tokens if word not in stopwords])\n",
    "    return text\n",
    " \n",
    " \n",
    "def senti_polarity(text):\n",
    "    \"\"\"\n",
    "    Return a sentiment polarity: 0 = negative, 1 = positive\n",
    "    \"\"\"\n",
    " \n",
    "    sentiment = 0.0\n",
    "    tokens_count = 0\n",
    " \n",
    "    text = clean_text(text)\n",
    "    print(text)\n",
    "    \n",
    "    token_word = word_tokenize(text)\n",
    "    \n",
    "    wrd_list = []\n",
    "    for word in token_word : \n",
    "        wrd_list.append(word)\n",
    "        #print(wrd_list)\n",
    "        \n",
    "        for x in range(len(wrd_list)):\n",
    "            for wd in wrd_list:\n",
    "                synsets = wn.synsets(wd)\n",
    "                if not synsets:\n",
    "                    continue\n",
    " \n",
    "            \n",
    "                synset = synsets[0]\n",
    "                swn_synset = swn.senti_synset(synset.name())\n",
    "                sentiment += swn_synset.pos_score() - swn_synset.neg_score()\n",
    "                tokens_count += 1\n",
    "                #print(sentiment)\n",
    " \n",
    "    \n",
    "    if not tokens_count:\n",
    "        print(\"No tokens\")\n",
    "       \n",
    "    f = open(\"negative-words.txt\", \"r\")\n",
    "    words2=f.read() \n",
    "    for wrd in wrd_list:\n",
    "        #print(wrd)\n",
    "        if wrd in words2:\n",
    "            print(wrd)\n",
    "            return -1\n",
    "    \n",
    "    # sum greater than 0 => positive sentiment\n",
    "    if sentiment >= 0:\n",
    "        return 1\n",
    "    \n",
    " \n",
    "    # negative sentiment\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "end=time.time()\n",
    "print(swn_polarity(\"A person is and bleeding\"))\n",
    "print(\"Time-Taken:\",end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
